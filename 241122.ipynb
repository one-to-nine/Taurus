{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 기본 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "import platform\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import backend as K\n",
    "import math\n",
    "import warnings\n",
    "import scipy.stats as stats  # for Q-Q plots\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import shap\n",
    "\n",
    "# 경고 무시\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 데이터 전처리 알고리즘(비지도 학습)\n",
    "# 문자데이터를 숫자로 변환해주는 알고리즘\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# 각 데이터의 범위를 비슷한 수준으로 조정하는 알고리즘(표준화)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# 교차검증\n",
    "# 평가 지표를 하나만 사용하는 경우\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# 평가 지표를 다수를 사용하는 경우\n",
    "from sklearn.model_selection import cross_validate\n",
    "# 교차 검증 방식\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 객체 저장\n",
    "import pickle\n",
    "\n",
    "# 회귀용 알고리즘\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# 회귀용 평가 함수\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_percentage_error\n",
    "# mse : 실제값에서 이론값을 빼고 제곱한 값을 평균한 값 (작을수록 좋음)\n",
    "\n",
    "# 분류용 머신러닝 알고리즘\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 분류용 평가 함수\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 차원축소\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 정확도를 확인하는 함수\n",
    "from sklearn.metrics import accuracy_score\n",
    "# MSE를 확인하는 함수\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "# 딥러닝 관련\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LeakyReLU, Dense, Activation, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Adagrad, Adamax\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "\n",
    "# 원핫인코딩\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임의 출력 행과 열을 모두 보이도록 설정\n",
    "pd.set_option('display.max_rows', None)  # 출력할 최대 행 개수를 None으로 설정\n",
    "pd.set_option('display.max_columns', None)  # 출력할 최대 열 개수를 None으로 설정\n",
    "pd.set_option('display.expand_frame_repr', False)  # 열이 화면을 넘어서지 않도록 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 설정\n",
    "\n",
    "# 한글 폰트 설정\n",
    "if platform.system() == 'Windows':\n",
    "    font_name = font_manager.FontProperties(fname='c:/Windows/Fonts/malgun.ttf').get_name()\n",
    "elif platform.system() == 'Darwin':  # Mac OS\n",
    "    font_name = 'AppleGothic'\n",
    "else:\n",
    "    font_name = 'NanumGothic'\n",
    "\n",
    "rc('font', family=font_name)\n",
    "\n",
    "# 폰트 설정 시 마이너스 기호가 깨짐 -> 방지하는 코드\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# palette 색상 설정 (기본 - 'tab10')\n",
    "palette = ['#4472C4', '#44A3C0', '#43BDA7', '#44B874', '#46B246', '#70AD47']   # 그라데이션\n",
    "palette2 = ['#7944E3', '#E9612C', '#4B87F7', '#EA346F', '#24C69A', '#F6C044']  # 대비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) ## 모든 열을 출력\n",
    "#pd.set_option('display.max_rows', None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 데이터 불러오기 (25℃)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Taurus_240820_2.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 그룹화\n",
    "group_RM = ['raw_material', 'RM_PSA_D50']\n",
    "group_PS = ['PS_Temp', 'PS_Ratio']\n",
    "group_etching = ['p-Si_pore_volume', 'p-Si_pore_size', 'p-Si_domain_size', 'p-Si_Oxygen']\n",
    "group_coating = ['C_condition', 'Carbon', 'c-Oxygen', 'c-Si_domain_size', 'c-Surface_area']\n",
    "group_cell = ['Li_capa_25', 'Deli_capa_1V_25', 'FCE_1V_25', 'Li_capa_45', 'Deli_capa_1V_45', 'FCE_1V_45']\n",
    "\n",
    "# 그룹 설정\n",
    "groups = [group_RM, group_PS, group_etching, group_coating, group_cell]\n",
    "row_titles = ['원료', '상분리', '에칭', '코팅', '셀 결과']\n",
    "\n",
    "# x축 이름 설정 딕셔너리\n",
    "xlabel_dict = {\n",
    "    'raw_material': '원료',\n",
    "    'RM_PSA_D50': '원료 PSA D50',\n",
    "    'PS_Temp': '상분리 온도',\n",
    "    'PS_Ratio': '상분리 Ratio',\n",
    "    'p-Si_pore_volume': 'p-Si Pore Volume',\n",
    "    'p-Si_pore_size': 'p-Si Pore Size',\n",
    "    'p-Si_domain_size': 'p-Si Domain Size',\n",
    "    'p-Si_Oxygen': 'p-Si Oxygen',\n",
    "    'C_condition': '코팅조건',\n",
    "    'Carbon': 'Carbon',\n",
    "    'c-Oxygen': 'c-Oxygen',\n",
    "    'c-Si_domain_size': 'c-Si Domain Size',\n",
    "    'c-Surface_area': 'c-Surface Area',\n",
    "    'FCETemp' : 'Temperature',\n",
    "    'LiCap' : 'Lithiation Capacity',\n",
    "    'DeliCap': 'Delithiation Capacity',\n",
    "    'FCE': 'FCE'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop(['Sample ID', 'raw_material'], axis = 1)\n",
    "\n",
    "mean_values = df.mean().round(2)\n",
    "std_values = df.std().round(2)\n",
    "min_values = df.min().round(2)\n",
    "max_values = df.max().round(2)\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    '평균': mean_values,\n",
    "    '표준편차': std_values,\n",
    "    '최소값': min_values,\n",
    "    '최대값': max_values\n",
    "})\n",
    "\n",
    "# xlabel_dict을 사용하여 인덱스 이름 변경\n",
    "summary.index = summary.index.map(xlabel_dict)\n",
    "\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = data.columns.tolist()\n",
    "print(column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data = data.drop(['Sample ID'], axis = 1)\n",
    "pre_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_corr = pre_data.drop(columns = ['raw_material']).corr().round(3)\n",
    "pre_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(pre_corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "plt.figure(figsize = (15, 15))\n",
    "sns.heatmap(pre_corr, linewidths = .3, annot = True, \n",
    "            fmt=\".2f\", cmap = 'coolwarm', mask = mask,\n",
    "            vmin = -1, vmax = 1, square = True, annot_kws={\"size\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output = False)\n",
    "\n",
    "# 범주형 변수만 선택하여 인코딩 수행\n",
    "# 여기서 2차원 형태로 데이터를 전달하기 위해 데이터프레임으로 선택\n",
    "encoded_data = encoder.fit_transform(pre_data[['raw_material']])\n",
    "# 결과를 pandas 데이터프레임으로 변환\n",
    "encoded_df = pd.DataFrame(encoded_data, columns = encoder.get_feature_names_out(['raw_material']))\n",
    "\n",
    "# 원래 데이터프레임과 결합\n",
    "data_final = pd.concat([pre_data.drop(columns=['raw_material']), encoded_df], axis=1)\n",
    "data_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력과 결과로 나눔\n",
    "X = data_final.drop(['LiCap', 'DeliCap', 'FCE'], axis = 1)\n",
    "y = data_final[['DeliCap', 'FCE']]\n",
    "\n",
    "display(X)\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X.columns.values\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화\n",
    "scaler1 = StandardScaler()\n",
    "X = scaler1.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.to_numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 머신러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터셋을 Train+Validation과 Test로 분할\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train_val.shape, X_test.shape, y_train_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 하이퍼파라미터 튜닝 범위 설정\n",
    "param_grids = {\n",
    "    'DecisionTreeRegressor': {\n",
    "        'max_depth': [None, 5, 10, 15, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10, 20],\n",
    "        'min_samples_leaf': [1, 2, 4, 8]\n",
    "    },\n",
    "    'RandomForestRegressor': {\n",
    "        'n_estimators': [50, 100, 200, 500],\n",
    "        'max_depth': [None, 5, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'bootstrap': [True, False]\n",
    "    },\n",
    "    'ExtraTreesRegressor': {\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'bootstrap': [True, False]\n",
    "    },    \n",
    "    'Ridge' : {\n",
    "        'alpha' : [0.1, 1.0, 10.0, 100.0]\n",
    "    },\n",
    "    'Lasso' : {\n",
    "        'alpha' : [0.1, 1.0, 10.0, 100.0]\n",
    "    },\n",
    "    'ElasticNet' : {\n",
    "        'alpha': [0.1, 1.0, 10.0],\n",
    "        'l1_ratio': [0.2, 0.5, 0.8]        \n",
    "    },\n",
    "    'XGBRegressor': {\n",
    "        'n_estimators': [50, 100, 200, 500],\n",
    "        'learning_rate': [0.01, 0.1, 0.05],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 1.0]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 모델 목록\n",
    "models = {\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(random_state=1),\n",
    "    'RandomForestRegressor': RandomForestRegressor(random_state=1),\n",
    "    'ExtraTreesRegressor' : ExtraTreesRegressor(random_state=1),\n",
    "    'Ridge' : Ridge(),\n",
    "    'Lasso' : Lasso(),\n",
    "    'ElasticNet' : ElasticNet(),\n",
    "    'XGBRegressor' : XGBRegressor(random_state=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. KFold 설정\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "results = {name: {'MAE': [], 'MAPE': [], 'MSE': [], 'RMSE': [], 'R2': []} for name in models.keys()}\n",
    "results_comparison = {name: {'Train': [], 'Validation': []} for name in models.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_targets = y_train_val.shape[1]  # 다중 타겟의 개수\n",
    "results = {\n",
    "    name: {metric: [[] for _ in range(num_targets)] for metric in ['MAE', 'MAPE', 'MSE', 'RMSE', 'R2']}\n",
    "    for name in models.keys()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name} 모델 하이퍼파라미터 튜닝 중...\")\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grids[name], cv=kf, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train_val, y_train_val)\n",
    "    \n",
    "    print(f\"최적의 하이퍼파라미터: {grid_search.best_params_}\")\n",
    "    print(f\"최소 MSE: {-grid_search.best_score_:.3f}\")\n",
    "\n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(X_train_val)):\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        model = grid_search.best_estimator_\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Training 예측 및 결과 저장\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        results_comparison[name]['Train'].append((y_train, y_train_pred))\n",
    "        \n",
    "        # Validation 예측 및 결과 저장\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        results_comparison[name]['Validation'].append((y_val, y_val_pred))\n",
    "\n",
    "        # 다중 타겟 성능 기록\n",
    "        for target_idx in range(y_val.shape[1]):\n",
    "            mae = mean_absolute_error(y_val[:, target_idx], y_val_pred[:, target_idx])\n",
    "            mape = mean_absolute_percentage_error(y_val[:, target_idx], y_val_pred[:, target_idx])\n",
    "            mse = mean_squared_error(y_val[:, target_idx], y_val_pred[:, target_idx])\n",
    "            rmse = mean_squared_error(y_val[:, target_idx], y_val_pred[:, target_idx], squared=False)\n",
    "            r2 = r2_score(y_val[:, target_idx], y_val_pred[:, target_idx])\n",
    "\n",
    "            results[name]['MAE'][target_idx].append(mae)\n",
    "            results[name]['MAPE'][target_idx].append(mape)\n",
    "            results[name]['MSE'][target_idx].append(mse)\n",
    "            results[name]['RMSE'][target_idx].append(rmse)\n",
    "            results[name]['R2'][target_idx].append(r2)\n",
    "\n",
    "    # 폴드별로 타겟 결과 출력\n",
    "    print(f\"\\n{name} Validation Results\")\n",
    "    for target_idx in range(y_train_val.shape[1]):\n",
    "        print(f\"\\nTarget {target_idx}\")\n",
    "        for fold_idx, (mae, mape, mse, rmse, r2) in enumerate(zip(\n",
    "                results[name]['MAE'][target_idx],\n",
    "                results[name]['MAPE'][target_idx],\n",
    "                results[name]['MSE'][target_idx],\n",
    "                results[name]['RMSE'][target_idx],\n",
    "                results[name]['R2'][target_idx])):\n",
    "            print(f\"Fold {fold_idx + 1}: MAE: {mae:.3f}, MAPE: {mape:.3f}, MSE: {mse:.3f}, \"\n",
    "                  f\"RMSE: {rmse:.3f}, R2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 다중 타겟 이름\n",
    "target_names = ['Delithiation Capacity', 'FCE']\n",
    "\n",
    "# K-Fold 및 Test 결과 그래프 그리기 함수\n",
    "def plot_results_by_target(results, target_names):\n",
    "    metrics = ['MAE', 'MAPE', 'MSE', 'RMSE', 'R2']\n",
    "    \n",
    "    for target_idx, target_name in enumerate(target_names):\n",
    "        fig, axes = plt.subplots(1, len(metrics), figsize=(20, 4), sharey=False)\n",
    "        fig.suptitle(f'K-Fold 성능 지표 - {target_name}', fontsize=16)\n",
    "        \n",
    "        for metric_idx, metric in enumerate(metrics):\n",
    "            ax = axes[metric_idx]\n",
    "            ax.set_title(metric)\n",
    "            ax.set_xlabel('Fold Number')\n",
    "            ax.set_ylabel(metric)\n",
    "\n",
    "            all_scores_across_models = []  # 모든 모델의 점수를 수집\n",
    "            for model_name, metrics_values in results.items():\n",
    "                # K-Fold 점수 추출\n",
    "                fold_scores = metrics_values[metric][target_idx]\n",
    "                folds = range(1, len(fold_scores) + 1)\n",
    "\n",
    "                # 그래프 그리기\n",
    "                label = model_name if metric_idx == 0 else None\n",
    "                ax.plot(folds, fold_scores, marker='o', label=label)\n",
    "                \n",
    "                all_scores_across_models.extend(fold_scores)\n",
    "\n",
    "            # 축 범위 설정: 최소값과 최대값을 기준으로 10% 여유 추가\n",
    "            min_val, max_val = min(all_scores_across_models), max(all_scores_across_models)\n",
    "            if min_val == max_val:\n",
    "                min_val, max_val = min_val - 1, max_val + 1  # 범위가 너무 좁은 경우\n",
    "            margin = 0.1 * (max_val - min_val)\n",
    "            ax.set_ylim(min_val - margin, max_val + margin)\n",
    "\n",
    "            ax.grid()\n",
    "        \n",
    "        # 범례를 그래프 오른쪽 외부에 위치\n",
    "        fig.legend(loc='center right', bbox_to_anchor=(1.15, 0.5))\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()\n",
    "\n",
    "# 함수 호출\n",
    "plot_results_by_target(results, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 타겟 성능 결과를 정리하는 데이터프레임 생성\n",
    "df_results = pd.DataFrame()\n",
    "\n",
    "# 알고리즘별로 데이터프레임에 결과 추가\n",
    "for algorithm, metrics in results.items():\n",
    "    for target_idx, target_name in enumerate(target_names):  # 다중 타겟 처리\n",
    "        target_metrics = {metric: metrics[metric][target_idx] for metric in metrics.keys()}\n",
    "        metric_df = pd.DataFrame(target_metrics)\n",
    "        metric_df.columns = pd.MultiIndex.from_product([[algorithm], [target_name], metric_df.columns])\n",
    "        df_results = pd.concat([df_results, metric_df], axis=1)\n",
    "\n",
    "# 폴드 인덱스 추가\n",
    "df_results.index = [f'Fold {i}' for i in range(1, len(df_results) + 1)]\n",
    "\n",
    "# 평균 및 표준 편차 계산\n",
    "means = df_results.mean(axis=0)\n",
    "stds = df_results.std(axis=0)\n",
    "\n",
    "# 평균 및 표준 편차를 데이터프레임에 추가\n",
    "df_results.loc['Mean'] = means\n",
    "df_results.loc['Standard deviation'] = stds\n",
    "\n",
    "# 데이터 형식 포맷팅 함수\n",
    "def format_value(value):\n",
    "    if isinstance(value, str):  # 문자열은 그대로 반환\n",
    "        return value\n",
    "    if pd.isna(value):  # NaN은 그대로 반환\n",
    "        return value\n",
    "    if value < 0.1:\n",
    "        return f\"{value:.3f}\"\n",
    "    elif value < 1:\n",
    "        return f\"{value:.2f}\"\n",
    "    elif value < 100:\n",
    "        return f\"{value:.1f}\"\n",
    "    else:\n",
    "        return f\"{int(value)}\"\n",
    "\n",
    "target_1_results = df_results.loc[:, df_results.columns.get_level_values(1) == \"Delithiation Capacity\"]\n",
    "target_1_results = target_1_results.applymap(format_value)\n",
    "target_1_results_transposed = target_1_results.transpose()\n",
    "\n",
    "\n",
    "target_2_results = df_results.loc[:, df_results.columns.get_level_values(1) == \"FCE\"]\n",
    "target_2_results = target_2_results.applymap(format_value)\n",
    "target_2_results_transposed = target_2_results.transpose()\n",
    "\n",
    "display(target_1_results_transposed)\n",
    "display(target_2_results_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제값과 예측값을 비교하는 그래프를 그리는 함수\n",
    "def plot_comparison_grid(results_comparison, target_names):\n",
    "    dataset_types = ['Train', 'Validation']\n",
    "    \n",
    "    for model_name, datasets in results_comparison.items():\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(8, 8), sharex=False, sharey=False)\n",
    "        fig.suptitle(f'Actual vs Predicted Values for {model_name}', fontsize=16)\n",
    "        \n",
    "        # 각 타겟에 대한 x축, y축의 공통 범위 계산\n",
    "        target_limits = []\n",
    "        for row, target_name in enumerate(target_names):\n",
    "            min_vals, max_vals = [], []\n",
    "            \n",
    "            # 각 데이터셋에서 최소값과 최대값 찾기\n",
    "            for dataset_type in dataset_types:\n",
    "                for y_true, y_pred in datasets[dataset_type]:\n",
    "                    min_vals.append(min(y_true[:, row].min(), y_pred[:, row].min()))\n",
    "                    max_vals.append(max(y_true[:, row].max(), y_pred[:, row].max()))\n",
    "\n",
    "            # 여유 범위 추가 (5%)\n",
    "            overall_min = min(min_vals)\n",
    "            overall_max = max(max_vals)\n",
    "            range_margin = (overall_max - overall_min) * 0.05\n",
    "            target_limits.append((overall_min - range_margin, overall_max + range_margin))\n",
    "        \n",
    "        # 그래프 그리기\n",
    "        for row, target_name in enumerate(target_names):\n",
    "            for col, dataset_type in enumerate(dataset_types):\n",
    "                ax = axes[row, col]\n",
    "                ax.set_title(f'{target_name} - {dataset_type}')\n",
    "                \n",
    "                # R² 점수 계산 및 그래프에 표시\n",
    "                r2_scores = []\n",
    "                color = palette[row]\n",
    "                for fold_idx, (y_true, y_pred) in enumerate(datasets[dataset_type]):\n",
    "                    r2 = r2_score(y_true[:, row], y_pred[:, row])\n",
    "                    r2_scores.append(r2)\n",
    "                    ax.scatter(y_true[:, row], y_pred[:, row], alpha=0.5, label=f'Fold {fold_idx+1}' if fold_idx == 0 else \"\")\n",
    "                r2 = np.mean(r2_scores)  # 폴드별 R² 점수의 평균\n",
    "\n",
    "                # R² 점수 텍스트로 표시\n",
    "                ax.text(0.05, 0.9, f'$R^2$: {r2:.2f}', transform=ax.transAxes, fontsize=12, verticalalignment='top')\n",
    "                min_limit, max_limit = target_limits[row]\n",
    "                ax.set_xlim(min_limit, max_limit)\n",
    "                ax.set_ylim(min_limit, max_limit)\n",
    "                ax.plot([min_limit, max_limit], [min_limit, max_limit], 'b--', lw=2)\n",
    "                ax.set_xlabel('True Values')\n",
    "                ax.set_ylabel('Predicted Values')\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # 제목 공간을 위해 여백 조정\n",
    "        plt.show()\n",
    "\n",
    "plot_comparison_grid(results_comparison, target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 지표별 Boxplot 그리기 함수\n",
    "def plot_boxplot_by_metrics_and_target(results, target_names):\n",
    "    metrics = ['MAE', 'MAPE', 'MSE', 'RMSE', 'R2']\n",
    "\n",
    "    for target_idx, target_name in enumerate(target_names):\n",
    "        fig, axes = plt.subplots(1, len(metrics), figsize=(20, 5), sharey=False)\n",
    "        fig.suptitle(f'성능 지표별 K-Fold Boxplot - {target_name}', fontsize=16)\n",
    "\n",
    "        for metric_idx, metric in enumerate(metrics):\n",
    "            ax = axes[metric_idx]\n",
    "            ax.set_title(metric)\n",
    "            ax.set_ylabel(metric)\n",
    "            \n",
    "            data = []\n",
    "            labels = []\n",
    "            for model_name, metrics_values in results.items():\n",
    "                # 다중 타겟에 맞게 데이터 추출\n",
    "                fold_scores = metrics_values[metric][target_idx]\n",
    "                data.append(fold_scores)\n",
    "                labels.append(model_name)\n",
    "\n",
    "            # Boxplot 그리기\n",
    "            box = ax.boxplot(data, labels=labels, patch_artist=True)\n",
    "            for patch, color in zip(box['boxes'], plt.cm.tab10.colors[:len(labels)]):\n",
    "                patch.set_facecolor(color)\n",
    "                            \n",
    "            # y축 범위 설정\n",
    "            all_scores = [score for fold_scores in data for score in fold_scores]\n",
    "            if all_scores:  # 데이터가 있을 경우에만 계산\n",
    "                min_val, max_val = min(all_scores), max(all_scores)\n",
    "                margin = 0.1 * (max_val - min_val)\n",
    "                ax.set_ylim(min_val - margin, max_val + margin)\n",
    "\n",
    "            ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()\n",
    "\n",
    "# 함수 호출\n",
    "plot_boxplot_by_metrics_and_target(results, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge, ElasticNet에 대한 최적 모델 및 파라미터 가져오기\n",
    "selected_models = ['Ridge', 'ElasticNet']\n",
    "best_estimators = {}\n",
    "\n",
    "# 각 모델에서 최적 하이퍼파라미터를 적용한 모델 준비\n",
    "for model_name in selected_models:\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=models[model_name],\n",
    "        param_grid=param_grids[model_name],\n",
    "        cv=kf,\n",
    "        scoring='neg_mean_squared_error'\n",
    "    )\n",
    "    grid_search.fit(X_train_val, y_train_val)\n",
    "    best_estimators[model_name] = grid_search.best_estimator_\n",
    "    print(f\"{model_name} - 최적의 하이퍼파라미터: {grid_search.best_params_}\")\n",
    "\n",
    "test_results = {}\n",
    "\n",
    "for model_name, model in best_estimators.items():\n",
    "    print(f\"\\n{model_name} 모델 Test 성능 평가 중...\")\n",
    "    \n",
    "    # Train+Validation 데이터로 재훈련\n",
    "    model.fit(X_train_val, y_train_val)\n",
    "    \n",
    "    # Test 데이터 예측\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # 성능 지표 계산\n",
    "    mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "    mse = mean_squared_error(y_test, y_test_pred)\n",
    "    rmse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "    r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # 결과 저장\n",
    "    test_results[model_name] = {\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2\n",
    "    }\n",
    "    \n",
    "    print(f\"Test 결과 - MAE: {mae:.3f}, MAPE: {mape:.3f}, MSE: {mse:.3f}, RMSE: {rmse:.3f}, R2: {r2:.3f}\")\n",
    "\n",
    "# Test 결과 출력\n",
    "print(\"\\nTest Results:\")\n",
    "\n",
    "df_test_results = pd.DataFrame(test_results).T\n",
    "df_test_results = df_test_results[['MAE', 'MAPE', 'MSE', 'RMSE', 'R2']]\n",
    "df_test_results = df_test_results.applymap(lambda x: f\"{x:.3f}\" if isinstance(x, (int, float)) else x)\n",
    "df_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_actual_vs_predicted_by_target(models, X_train_val, y_train_val, X_test, y_test, target_names):\n",
    "    for model_name, model in models.items():\n",
    "        # Train+Validation 데이터에 대한 예측값\n",
    "        y_train_val_pred = model.predict(X_train_val)\n",
    "\n",
    "        # Test 데이터에 대한 예측값\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        # 그래프 설정\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(8, 6))\n",
    "        fig.suptitle(f\"Actual vs Predicted - {model_name}\", fontsize=16)\n",
    "\n",
    "        datasets = [\n",
    "            ('Train+Validation', y_train_val, y_train_val_pred, palette[0]),\n",
    "            ('Test', y_test, y_test_pred, palette[3])\n",
    "        ]\n",
    "\n",
    "        for target_idx, target_name in enumerate(target_names):\n",
    "            for col, (dataset_name, y_true, y_pred, color) in enumerate(datasets):\n",
    "                ax = axes[target_idx, col]\n",
    "                ax.scatter(\n",
    "                    y_true[:, target_idx], \n",
    "                    y_pred[:, target_idx], \n",
    "                    alpha=0.5, \n",
    "                    color=color, \n",
    "                    label=f'{dataset_name}'\n",
    "                )\n",
    "                ax.set_title(f'{target_name} - {dataset_name} Data')\n",
    "                ax.set_xlabel('True Values')\n",
    "                ax.set_ylabel('Predicted Values')\n",
    "                ax.legend()\n",
    "\n",
    "                min_val = min(y_true[:, target_idx].min(), y_pred[:, target_idx].min())\n",
    "                max_val = max(y_true[:, target_idx].max(), y_pred[:, target_idx].max())\n",
    "                ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # 제목 간격 조정\n",
    "        plt.show()\n",
    "\n",
    "# Ridge, Lasso, ElasticNet 모델에 대해 타겟별 그래프 생성\n",
    "plot_actual_vs_predicted_by_target(\n",
    "    models=best_estimators,  # 최적 모델들\n",
    "    X_train_val=X_train_val,\n",
    "    y_train_val=y_train_val,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    target_names=['Lithiation Capacity', 'Delithiation Capacity']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_models = sorted(results.items(), key=lambda x: np.mean(x[1]['R2']), reverse=True)\n",
    "\n",
    "# 2. 각 모델의 feature importance 추출 및 subplot 시각화\n",
    "for model_name in selected_models:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharey=False)\n",
    "    fig.suptitle(f\"Feature Importance - {model_name}\", fontsize=16)\n",
    "    \n",
    "    for target_idx, target_name in enumerate(target_names):\n",
    "        model = models[model_name]  # 선택한 모델 객체 가져오기\n",
    "        model.fit(X_train_val, y_train_val[:, target_idx])  # 개별 타겟에 대해 학습 수행\n",
    "\n",
    "        # Feature Importance가 존재하는 모델인지 확인 후 시각화\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            feature_importances = model.feature_importances_\n",
    "        elif hasattr(model, 'coef_'):\n",
    "            feature_importances = np.abs(model.coef_)\n",
    "        else:\n",
    "            print(f\"{model_name}는 Feature Importance를 제공하지 않음\")\n",
    "            continue\n",
    "\n",
    "        # 각 subplot에 feature importance 시각화\n",
    "        ax = axes[target_idx]\n",
    "        ax.barh(range(len(feature_importances)), feature_importances, align='center')\n",
    "        ax.set_title(f'{target_name}')\n",
    "        ax.set_xlabel('Importance')\n",
    "        ax.set_yticks(range(len(feature_importances)))\n",
    "        ax.set_yticklabels(feature_names)\n",
    "        ax.invert_yaxis()  # 중요도가 높은 순으로 정렬\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # 제목 여백 조정\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = models['Ridge']\n",
    "best_ridge_model = GridSearchCV(estimator=save_model, param_grid=param_grids['Ridge'], cv=kf, scoring='neg_mean_squared_error').fit(X_train_val, y_train_val).best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_ridge_model_241122.pkl', 'wb') as file:\n",
    "    pickle.dump(best_ridge_model, file)\n",
    "    pickle.dump(encoder, file)\n",
    "    pickle.dump(scaler1, file)\n",
    "print(\".pkl 형식으로 성공적으로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4 모델 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_ridge_model_241122.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "    encoder = pickle.load(file)\n",
    "    scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame({\n",
    "    'raw_material': ['S6'],  # 범주형 변수\n",
    "    'RM_PSA_D50': [5],           # 나머지 수치형 피처\n",
    "    'PS_Temp': [845],\n",
    "    'PS_Ratio' : [0.85],\n",
    "    'p-Si_pore_volume' : [0.81],\n",
    "    'p-Si_pore_size' : [3.11],\n",
    "    'p-Si_domain_size' : [2],\n",
    "    'p-Si_Oxygen' : [1],\n",
    "    'C_condition' : [200],\n",
    "    'Carbon' : [41.3],\n",
    "    'c-Oxygen' : [1.4],\n",
    "    'c-Si_domain_size' : [2.1],\n",
    "    'c-Surface_area' : [19.8],\n",
    "    'FCETemp' : [25]\n",
    "})\n",
    "\n",
    "encoded_new_data = encoder.transform(new_data[['raw_material']])\n",
    "encoded_df = pd.DataFrame(encoded_new_data, columns=encoder.get_feature_names_out(['raw_material']))\n",
    "processed_new_data = pd.concat([new_data.drop(columns=['raw_material']), encoded_df], axis=1)\n",
    "scaled_new_data = scaler.transform(processed_new_data)\n",
    "predicted_y = model.predict(scaled_new_data)\n",
    "\n",
    "print(\"예측 결과:\", predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.6 최적의 조건 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적화 성공! 목표 y 값에 가장 가까운 X (스케일링 전): \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RM_PSA_D50</th>\n",
       "      <th>PS_Temp</th>\n",
       "      <th>PS_Ratio</th>\n",
       "      <th>p-Si_pore_volume</th>\n",
       "      <th>p-Si_pore_size</th>\n",
       "      <th>p-Si_domain_size</th>\n",
       "      <th>p-Si_Oxygen</th>\n",
       "      <th>C_condition</th>\n",
       "      <th>Carbon</th>\n",
       "      <th>c-Oxygen</th>\n",
       "      <th>c-Si_domain_size</th>\n",
       "      <th>c-Surface_area</th>\n",
       "      <th>FCETemp</th>\n",
       "      <th>raw_material</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.358585</td>\n",
       "      <td>848.168329</td>\n",
       "      <td>0.950752</td>\n",
       "      <td>0.875013</td>\n",
       "      <td>3.216672</td>\n",
       "      <td>2.128926</td>\n",
       "      <td>1.062308</td>\n",
       "      <td>421.527718</td>\n",
       "      <td>41.828418</td>\n",
       "      <td>1.384615</td>\n",
       "      <td>2.416963</td>\n",
       "      <td>6.747692</td>\n",
       "      <td>25.0</td>\n",
       "      <td>DS8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RM_PSA_D50     PS_Temp  PS_Ratio  p-Si_pore_volume  p-Si_pore_size  p-Si_domain_size  p-Si_Oxygen  C_condition     Carbon  c-Oxygen  c-Si_domain_size  c-Surface_area  FCETemp raw_material\n",
       "0    9.358585  848.168329  0.950752          0.875013        3.216672          2.128926     1.062308   421.527718  41.828418  1.384615          2.416963        6.747692     25.0          DS8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당 x 인자로 예측한 Delithiation capacity:  1800.0 mAh/g\n",
      "해당 x 인자로 예측한 FCE:  85.7 %\n"
     ]
    }
   ],
   "source": [
    "# 저장된 모델 및 관련 객체 로드\n",
    "with open('best_ridge_model_241122.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)  # Ridge 모델\n",
    "    encoder = pickle.load(file)  # Encoder (OneHotEncoder)\n",
    "    scaler = pickle.load(file)  # Scaler (StandardScaler)\n",
    "\n",
    "# 특정 y 값을 출력하기 위한 X값 찾기\n",
    "target_y = np.array([1800, 89])  # 목표 y 값 (사용자가 원하는 출력값)\n",
    "\n",
    "# 입력 데이터 예시\n",
    "initial_data = pd.DataFrame({\n",
    "    'raw_material': ['S6'],  # 초기 범주형 값\n",
    "    'RM_PSA_D50': [5],\n",
    "    'PS_Temp': [845],\n",
    "    'PS_Ratio': [0.85],\n",
    "    'p-Si_pore_volume': [0.81],\n",
    "    'p-Si_pore_size': [3.11],\n",
    "    'p-Si_domain_size': [2],\n",
    "    'p-Si_Oxygen': [1],\n",
    "    'C_condition': [200],\n",
    "    'Carbon': [41.3],\n",
    "    'c-Oxygen': [1.4],\n",
    "    'c-Si_domain_size': [2.1],\n",
    "    'c-Surface_area': [19.8],\n",
    "    'FCETemp': [25]\n",
    "})\n",
    "\n",
    "# 초기 추정값을 위한 전처리 과정\n",
    "encoded_initial_data = encoder.transform(initial_data[['raw_material']])\n",
    "encoded_df = pd.DataFrame(encoded_initial_data, columns=encoder.get_feature_names_out(['raw_material']))\n",
    "processed_initial_data = pd.concat([initial_data.drop(columns=['raw_material']), encoded_df], axis=1)\n",
    "scaled_initial_data = scaler.transform(processed_initial_data)\n",
    "initial_guess = scaled_initial_data[0]  # 초기 추정값 설정\n",
    "\n",
    "# FCETemp의 인덱스를 찾아서 해당 값을 고정\n",
    "fce_temp_index = processed_initial_data.columns.get_loc('FCETemp')\n",
    "fixed_value = scaled_initial_data[0, fce_temp_index]  # FCETemp의 고정된 스케일링 값\n",
    "\n",
    "# FCETemp를 제외한 나머지 변수들만 추정값 설정\n",
    "variable_indices = [i for i in range(initial_guess.shape[0]) if i != fce_temp_index]\n",
    "initial_guess_variables = initial_guess[variable_indices]\n",
    "\n",
    "# 최적화 목표 함수 정의\n",
    "def objective_function(X):\n",
    "    # X를 전체 변수로 확장하여 FCETemp 값 고정\n",
    "    full_X = np.insert(X, fce_temp_index, fixed_value)\n",
    "    full_X_reshaped = full_X.reshape(1, -1)\n",
    "    try:\n",
    "        y_pred = model.predict(full_X_reshaped)  # 예측값\n",
    "    except ValueError as e:\n",
    "        print(\"예측 중 오류 발생: \", e)\n",
    "        return np.inf  # 오류 발생 시 큰 값을 반환하여 해당 경로를 피하도록 함\n",
    "    # np.linalg.norm : 두 값 간의 유클리드 거리(오차)를 계산하여, 최적화 알고리즘이 이 값을 최소화하도록 함\n",
    "    return np.linalg.norm(y_pred - target_y)  # 예측값과 목표 y의 차이를 최소화\n",
    "\n",
    "# 변수의 경계 설정 (양수 범위로 설정, FCETemp를 제외한 나머지 변수들에 대한 경계 설정)\n",
    "bounds = [(0, 2) for _ in range(len(variable_indices))]\n",
    "\n",
    "# 최적화 실행 (최적화 방법을 'L-BFGS-B'로 변경하고 경계를 설정)\n",
    "tol = 1e-5  # 허용 오차 설정\n",
    "result = minimize(objective_function, initial_guess_variables, method='L-BFGS-B', bounds=bounds, options={'gtol': tol, 'disp': True, 'maxiter': 1000})\n",
    "\n",
    "# 최적화된 결과 출력\n",
    "if result.success:\n",
    "    # 최적화된 값을 전체 변수로 확장하여 FCETemp 포함\n",
    "    optimized_variables = result.x\n",
    "    optimized_full = np.insert(optimized_variables, fce_temp_index, fixed_value)\n",
    "    optimized_scaled = optimized_full.reshape(1, -1)\n",
    "    optimized_unscaled = scaler.inverse_transform(optimized_scaled)\n",
    "    optimized_df = pd.DataFrame(optimized_unscaled, columns=processed_initial_data.columns)\n",
    "    \n",
    "    # Encoding 된 항목 복원 (예: 'raw_material')\n",
    "    encoded_columns = encoder.get_feature_names_out(['raw_material'])\n",
    "    encoded_values = optimized_df[encoded_columns].values\n",
    "    decoded_value = encoder.inverse_transform(encoded_values)[0]  # 원래 범주형 값 복원\n",
    "    optimized_df = optimized_df.drop(columns=encoded_columns)  # 인코딩된 열 제거\n",
    "    optimized_df['raw_material'] = decoded_value  # 원래 범주형 값 추가\n",
    "    \n",
    "    print(\"최적화 성공! 목표 y 값에 가장 가까운 X (스케일링 전): \")\n",
    "    display(optimized_df)\n",
    "    # print(\"해당 x 인자로 예측한 값: \", model.predict(optimized_scaled))\n",
    "    print(\"해당 x 인자로 예측한 Delithiation capacity: \", model.predict(optimized_scaled)[0][0].round(1), \"mAh/g\")\n",
    "    print(\"해당 x 인자로 예측한 FCE: \", model.predict(optimized_scaled)[0][1].round(1), \"%\")\n",
    "else:\n",
    "    print(\"최적화 실패: \", result.message)\n",
    "    print(\"최적화 시도 중의 마지막 X 값: \", result.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 딥러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80%: train + validation, 20%: test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# train과 validation으로 다시 분할 (75%: train, 25%: validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25)\n",
    "\n",
    "# 분할된 데이터의 크기 확인\n",
    "print(f\"Train set: {X_train.shape, y_train.shape}, Validation set: {X_val.shape, y_val.shape}, Test set: {X_test.shape, y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정규화 (표준화)\n",
    "scaler_X = StandardScaler()\n",
    "X_train = scaler_X.fit_transform(X_train)   # Train 데이터에 대해 fitting하고 변환\n",
    "X_val = scaler_X.transform(X_val)   # Validation과 Test 데이터는 fitting된 scaler로 변환만 수행\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "# y에 대한 표준화\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(y_train)\n",
    "y_val = scaler_y.transform(y_val)\n",
    "y_test = scaler_y.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 모델 설계를 위한 설정 값\n",
    "\n",
    "input_dim = len(X_train[0])\n",
    "output_dim = 2\n",
    "\n",
    "# 오차를 구하는 함수\n",
    "# 회귀\n",
    "loss_function = 'mean_squared_error'\n",
    "# 2진 분류\n",
    "# loss_function = 'binary_crossentropy'\n",
    "# 다중 분류\n",
    "# loss_function = 'categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 설계 함수\n",
    "def add_dense_block(model, units, alpha=0.01):\n",
    "    model.add(Dense(units))\n",
    "    model.add(LeakyReLU(alpha=alpha))\n",
    "    model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망을 설계한다.\n",
    "\n",
    "# 강사님의 신경망 설계 방법!\n",
    "# 일반적인 방법은 없지만 강사님이 사용하는 방법임\n",
    "# 국제적으로 인정받은 방식은 아니지만 프로젝트 실행하면서 이렇게 하니 결과가 좋았던 적이 많았음\n",
    "# 첫번째 은닉층의 노드의 개수를 입력 데이터 컬럼의 개수의 1.2배로 설정\n",
    "# 두번째부터는 이전 은닉층의 노드의 개수 80% 수준으로 설정\n",
    "# 출력층의 노드의 개수보다 적어지지 않도록 설정\n",
    "# 예) 컬럼 10개면 첫번째 은닉층 노드 : 12개 -> 두번째는 12x0.8개 = 9.6개 (10개) -> 세번째는 10x0.8개 = 8개 -> ... 출력층 1개일 때까지\n",
    "\n",
    "\n",
    "# 신경망의 구조를 관리하는 객체\n",
    "# 여기에 추가한 레이어 순서대로 데이터가 통과한다.\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(20, input_dim = input_dim, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "add_dense_block(model, 16)\n",
    "add_dense_block(model, 12)\n",
    "add_dense_block(model, 10)\n",
    "add_dense_block(model, 8)\n",
    "add_dense_block(model, 6)\n",
    "          \n",
    "# 출력층\n",
    "# 출력층은 최종 결과를 예측하는 계산하는 부분\n",
    "# 노드의 개수는 예측하고자 하는 데이터의 가지수로 설정해줌\n",
    "# 선형 회귀 레이어\n",
    "model.add(Dense(output_dim))\n",
    "# 회귀는 출력층의 활성화 함수를 두지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 경사 하강법\n",
    "optimzier = Adam(learning_rate = 0.001)\n",
    "\n",
    "# 학습모델 컴파일\n",
    "model.compile(loss = loss_function, optimizer = optimzier) # metrics는 회귀일때는 설정 안하고 분류일 때 accuracy 설정\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자동 저장 callback\n",
    "path = '241122.keras'\n",
    "callback1 = ModelCheckpoint(filepath=path, monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OriginalScaleLoss(Callback):\n",
    "    def __init__(self, X_train, y_train_scaled, X_val, y_val_scaled, scaler_y):\n",
    "        super().__init__()\n",
    "        self.X_train = X_train\n",
    "        self.y_train_scaled = y_train_scaled\n",
    "        self.X_val = X_val\n",
    "        self.y_val_scaled = y_val_scaled\n",
    "        self.scaler_y = scaler_y\n",
    "        self.train_rmse_per_output = []\n",
    "        self.val_rmse_per_output = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # 훈련 데이터 예측\n",
    "        y_train_pred_scaled = self.model.predict(self.X_train, verbose=0)\n",
    "        y_train_pred = self.scaler_y.inverse_transform(y_train_pred_scaled)\n",
    "        y_train_true = self.scaler_y.inverse_transform(self.y_train_scaled)\n",
    "\n",
    "        # 검증 데이터 예측\n",
    "        y_val_pred_scaled = self.model.predict(self.X_val, verbose=0)\n",
    "        y_val_pred = self.scaler_y.inverse_transform(y_val_pred_scaled)\n",
    "        y_val_true = self.scaler_y.inverse_transform(self.y_val_scaled)\n",
    "\n",
    "        # 출력 차원별 RMSE 계산\n",
    "        train_rmse_per_output = np.sqrt(np.mean((y_train_true - y_train_pred) ** 2, axis=0))\n",
    "        val_rmse_per_output = np.sqrt(np.mean((y_val_true - y_val_pred) ** 2, axis=0))\n",
    "\n",
    "        # 손실 값 저장\n",
    "        self.train_rmse_per_output.append(train_rmse_per_output)\n",
    "        self.val_rmse_per_output.append(val_rmse_per_output)\n",
    "\n",
    "        # 출력 차원별로 RMSE 출력\n",
    "        for idx, (train_rmse, val_rmse) in enumerate(zip(train_rmse_per_output, val_rmse_per_output)):\n",
    "            print(f\"Epoch {epoch+1} - 출력 차원 {idx+1}: Train RMSE = {train_rmse:.4f}, Val RMSE = {val_rmse:.4f}\")\n",
    "\n",
    "# 콜백 인스턴스 생성\n",
    "original_scale_loss = OriginalScaleLoss(\n",
    "    X_train=X_train,            # 학습 데이터 입력\n",
    "    y_train_scaled=y_train,     # 학습 데이터 출력 (스케일된 값)\n",
    "    X_val=X_test,               # 검증 데이터 입력\n",
    "    y_val_scaled=y_test,        # 검증 데이터 출력 (스케일된 값)\n",
    "    scaler_y=scaler_y        # 출력값을 스케일링한 스케일러\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조기 중단\n",
    "callback2 = EarlyStopping(monitor='val_loss', patience=100)\n",
    "callback3 = original_scale_loss\n",
    "\n",
    "# 학습을 한다.\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                    epochs=9999999999, batch_size=128, callbacks=[callback1, callback2, callback3])\n",
    "\n",
    "# batch_size보다 데이터의 수가 작으면 데이터의 수만큼만 올라가서 상관없음\n",
    "# 하지만 gpu를 많이 잡아먹음. gpu 여유있으면 batch size 크게 잡아주는 것이 좋음\n",
    "# val_loss가 떨어지지 않으면 layer 수가 부족한 것이니 layer를 늘려주면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차에 관한 그래프\n",
    "plt.plot(history.history['loss'][:-10], label='Train')\n",
    "plt.plot(history.history['val_loss'][:-10], label='Validation')\n",
    "# plt.ylim(0, 5)   # train loss 그래프가 구불부굴함 -> 학습 덜 된 것임 -> batch size 늘려서 완만해지게 만들어야 함\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 그래프가 구불구불한 것은 batch size 늘리면 나아짐 -> batch size 가 작으면 학습이 불안정해짐. 데이터 양이 많으면 한꺼번에 메모리에 올릴 수 없어서 쪼개서 올려주는 것임\n",
    "# 선생님은 32 -> 50000으로 늘려서 진행함. 한번에 많이 늘리면 메모리 부족하다는 경고가 뜸. 천천히 늘려가면서 학습이 되면 더 늘려주면 됨\n",
    "# train와 test loss 그래프가 맞닿아 있고 완만해 있으면 학습이 잘 되었다는 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Test set 평가\n",
    "test_loss, test_mse = model.evaluate(X_test, y_test)\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 평가를 수행한다.\n",
    "# 저장한 학습 모델을 불러온다.\n",
    "best_model = load_model('241122.keras')\n",
    "\n",
    "# 데이터에 대한 예측값\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# 각 y값에 대한 MSE 계산 (학습 및 검증 데이터)\n",
    "mse_train_list = []\n",
    "mse_val_list = []\n",
    "mse_test_list = []\n",
    "\n",
    "for i, col in enumerate(y.columns):\n",
    "    mse_train = mean_squared_error(y_train[:, i], y_train_pred[:, i])\n",
    "    mse_val = mean_squared_error(y_test[:, i], y_val_pred[:, i])\n",
    "    mse_test = mean_squared_error(y_test[:, i], y_test_pred[:, i])\n",
    "    mse_train_list.append(round(mse_train, 2))\n",
    "    mse_val_list.append(round(mse_val, 2))\n",
    "    mse_test_list.append(round(mse_test, 2))\n",
    "\n",
    "# 결과를 데이터프레임으로 출력\n",
    "mse_df = pd.DataFrame({\n",
    "    'Output': y.columns,\n",
    "    'MSE_Train': mse_train_list,\n",
    "    'MSE_Val': mse_val_list,\n",
    "    'MSE_Test': mse_test_list\n",
    "})\n",
    "\n",
    "display(mse_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 값과 예측 값을 비교하는 그래프를 그리는 함수.\n",
    "\n",
    "def plot_comparison(y_actual, y_pred, columns, scaler=None):\n",
    "    # 스케일링 전 값으로 역변환\n",
    "    if scaler is not None:\n",
    "        y_actual = scaler.inverse_transform(y_actual)\n",
    "        y_pred = scaler.inverse_transform(y_pred)\n",
    "    \n",
    "    for i, col in enumerate(columns):  # 열 이름을 가져옴\n",
    "        # 서브플롯 설정 (1행 2열, 첫 번째 서브플롯은 라인 그래프, 두 번째는 산점도)\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "        # 왼쪽 서브플롯: 라인 그래프\n",
    "        axes[0].plot(y_actual[:, i].reshape(-1), label=f'Actual {col}')\n",
    "        axes[0].plot(y_pred[:, i].reshape(-1), label=f'Predict {col}', linestyle='--')\n",
    "        axes[0].legend()\n",
    "        axes[0].set_title(f'Actual vs Predicted (Line Plot) for {col}')\n",
    "\n",
    "        # 오른쪽 서브플롯: 산점도 그래프\n",
    "        axes[1].scatter(y_actual[:, i].reshape(-1), y_pred[:, i].reshape(-1))\n",
    "        axes[1].plot([min(y_actual[:, i]), max(y_actual[:, i])], \n",
    "                     [min(y_actual[:, i]), max(y_actual[:, i])], \n",
    "                     color='red', linestyle='--')  # 대각선 (완벽한 예측선)\n",
    "        axes[1].set_title(f'Actual vs Predicted (Scatter Plot) for {col}')\n",
    "        axes[1].set_xlabel(f'Actual {col}')\n",
    "        axes[1].set_ylabel(f'Predicted {col}')\n",
    "\n",
    "        # 그래프 간격 조정\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(wspace=0.4)  # 서브플롯 간의 가로 간격 조정 (wspace=0.4로 설정)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 결과\n",
    "y_pred = best_model.predict(X_train)\n",
    "plot_comparison(y_train, y_pred, y.columns, scaler=scaler_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 결과\n",
    "y_pred_val = best_model.predict(X_val)\n",
    "plot_comparison(y_val, y_pred_val, y.columns, scaler=scaler_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습이 완료된 모델을 저장해준다.\n",
    "with open('best_DL_model_241122.pkl', 'wb') as fp:\n",
    "    # 학습 모델 저장\n",
    "    pickle.dump(best_model, fp)\n",
    "    # 스케일러 저장\n",
    "    pickle.dump(scaler_X, fp)\n",
    "    pickle.dump(scaler_y, fp)\n",
    "    # 인코더 저장\n",
    "    pickle.dump(encoder, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 딥러닝 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장한 학습모델들을 복원한다.\n",
    "with open('best_model_241122.pkl', 'rb') as fp:\n",
    "    # 학습 모델 불러오기\n",
    "    model = pickle.load(fp)\n",
    "    # 스케일러 불러오기\n",
    "    scaler1 = pickle.load(fp)\n",
    "    scaler2 = pickle.load(fp)\n",
    "    # 인코더 불러오기\n",
    "    encoder1 = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1 값으로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 csv파일로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.read_csv('combinations_data.csv')\n",
    "prediction.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_encoded = encoder1.transform(prediction[['raw_material']])\n",
    "# 결과를 pandas 데이터프레임으로 변환\n",
    "prediction_encoded = pd.DataFrame(prediction_encoded, columns=encoder1.get_feature_names_out(['raw_material']))\n",
    "prediction_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.concat([prediction.drop(columns=['raw_material']), prediction_encoded], axis=1)\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중공선성 문제 해결을 위해 dummy column 1개 삭제\n",
    "# 학습할 때와 동일하게 진행\n",
    "new_data = new_data.drop(['raw_material_S5'], axis = 1)\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화\n",
    "X = scaler1.transform(new_data)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "pred = model.predict(X)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원래의 결과로 복원\n",
    "result = scaler2.inverse_transform(pred)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 결과를 새로운 데이터프레임에 추가\n",
    "# y_new_pred는 (샘플 수, 3) 크기의 배열이므로 이를 각각의 열로 분리하여 추가\n",
    "prediction['Lithiation Capacity (예측값)'] = result[:, 0].astype(int)  # 첫 번째 출력값을 정수로 변환\n",
    "prediction['Delithiation Capacity (예측값)'] = result[:, 1].astype(int)  # 두 번째 출력값을 정수로 변환\n",
    "prediction['FCE (예측값)'] = result[:, 2].round(1)  # 세 번째 출력값은 소수점 첫째짜리 까지 반환\n",
    "prediction.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeliCap을 기준으로 내림차순 정렬하고, 값이 동일하면 FCE를 기준으로 정렬\n",
    "prediction_sorted = prediction.sort_values(by=['Delithiation Capacity (예측값)', 'FCE (예측값)'], ascending=[False, False])\n",
    "\n",
    "# 결과를 csv 파일로 저장\n",
    "prediction_sorted.to_csv('Taurus_Prediction_Result_241014.csv', encoding='utf-8-sig', index=False)\n",
    "\n",
    "print(\"예측이 완료되었습니다. 결과는 'Taurus_Prediction_Result_241122.csv'에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
